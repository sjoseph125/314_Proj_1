---
title: 'Unit 2 Project: Further Analysis of Video Games Dataset'
authors: 'Samson Joseph, Sean Simmons, Daniel Gurwah, Joseph Difrancesco'
date: "null"
output:
  html_document:
    df_print: paged
---
## Delete lines 8 - 16 section before submitting the file
This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook to use as a template for your Unit 2 Project. 

Add new chunks by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).  You may need to Knit to HTML, using the KNIT button on the toolbar. 

You will submit both the saved R Markdown file (.RMD) WITH A NEW NAME and the HTML file.
## Delete lines 8-16 before submitting the file.

**To:** DR. Random<br> 

**From:** Samson Joseph, Sean Simmons, Daniel Gurwah, Christopher Aguila, Joseph Difrancesco<br>

**Subject:** Further Analysis of Video Games Dataset 


## Background
After our initial analysis of the Video Games dataset, we have now been tasked with applying inferential statistics to further interpret the data. Once again, the dataset is an aggregation of data collected from Metacritic and VGCharts, which contains the following fields: Name, Platform, Year_of_Release, Genre, Publisher, NASales, EUSales, JPSales, OtherSales, Global_Sales, Critic_Score, Critic_Count, User_Score, User_Count, Developer, and Rating. These fields provide information about the sales, by several defined regions, as well as the reception from critics and users of 16,719 video games released between the years 1986 and 2016. Within the dataset, there were only ~6,900 observations that were complete. Other observations were: tbh, N/A and blank. None of those are the proper value for NA in R. In order to resolve this issue, we first used Excel to change all tbh and N/A to the proper NA value in the dataset. Then we used R to change all blank observations to NA as well. We also had to change all of the variables to the proper data type, which we did in R. See the table below for a more detailed breakdown of the variables, their type, and what they are. 

```{r setup, include =FALSE}
#Loading Libraries
library(tidyverse)
#library(inference)
library(statsr)
#Loading Dataset
vgs <- read.csv('replaced variables.csv')

#Transforming variables to appropriate data types
vgs$NA_Sales<-as.numeric(vgs$NA_Sales)
vgs$EU_Sales<-as.numeric(vgs$EU_Sales)
vgs$JP_Sales<-as.numeric(vgs$JP_Sales)
vgs$Other_Sales<-as.numeric(vgs$Other_Sales)
vgs$Platform <- as.factor(vgs$Platform)
vgs$Publisher <- as.factor(vgs$Genre)
vgs$Genre <- as.factor(vgs$Genre)
vgs$Developer <- as.factor(vgs$Developer)
vgs$Rating <- as.factor(vgs$Rating)
vgs$Year_of_Release <- as.factor(vgs$Year_of_Release)
vgs$User_Score <- as.numeric(vgs$User_Score)
vgs$Name <- as.character(vgs$Name)
vgs$User_Score <- vgs$User_Score * 10

#Replacing empty entries with NA
vgs$Rating[vgs$Rating %in% c("")]<- NA
vgs$Rating <-factor(vgs$Rating)
vgs$Developer[vgs$Developer %in% c("")]<- NA
vgs$Developer <-factor(vgs$Developer)
vgs$Genre[vgs$Genre %in% c("")]<- NA
vgs$Genre <-factor(vgs$Genre)
vgs <- filter(vgs, Name != "")
```
## Inference Analyses

### Analysis 1: One Mean -[NA_Sales]
#### Analyst:[Sean Simmons]

The variable being analyzed is the critic score, for which we have 8137 observations within the dataset. In the analysis, I will be comparing our sample to a self-reported critic-score average published by Metacritic [ https://www.metacritic.com/publication/total-video-games ], which states that the average critic score is 74.4. In order to produce a confidence interval, I first needed to see that our data met the conditions to use CLT. Our sample contains less than 10% of all scores made by critics. There are ~1,200,000 games [ https://gamingshift.com/how-many-video-games-exist/#:~:text=After doing some research%2C our, games for the Nintendo Switch. ] in existence and counting, so I am assuming that our sample size meets these criteria. The values are independent, as they are aggregated from many different critics reviewing unique games. However, the sample was not random so this data does not meet conditions for CLT. The data has a slight left skew but is mostly normal. Since our sample size is so large, at 8137, we can assume its normality and use the t-test. As such, we are 95% confident that the true mean of critic scores for video games is between 68.66479 and 69.27057.

In this hypothesis test, the null hypothesis is that the average critic score provided by Metacritic is the same as the mean critic score generated by our own dataset, and our alternative hypothesis is that the average critic score provided by Metacritic is not equal to the mean critic score generated by our own dataset. I am using a two-tailed test because we are interested in whether there is any difference between our null and our alternative, whether that difference is negative or positive. Running the t-test, we get a t-value of -45.512 and a p-value of 2.2e-16. Therefore, we should reject the null hypothesis, because our p-value is much smaller than our significance level at 0.05. Looking back at the confidence interval ( 68.66479, 69.27057 ), we can see further evidence to support this conclusion, since it suggests a difference that is less than our null. This is interesting because a portion of our sample comes from a webscrape of Metacritic. This may imply that critic scores hosted by VGCharts tend to have a lower value.

As previously mentioned, I am comparing this statistic to the self-reported critic-score average published by Metacritic. This statistic is a bit convoluted since it is only noted within individual critic profiles to highlight the difference between that critic's average score and Metacritic's aggregated average for all critics. Neither the population size nor method used is known as to how Metacritic generated this number.

=======
```{r}

#extract the critic_score variable from the vgs dataset w/ NA observations removed
critic_score1 <- vgs$Critic_Score[!is.na(vgs$Critic_Score)]
#view / check new variable: critic_score1
view(critic_score1)
str(critic_score1)
summary(critic_score1)
#histogram visualization
ggplot() + geom_histogram(mapping = aes(x = critic_score1), binwidth = .1)

###+++++++++++++++++

### T test
t.test(critic_score1, conf.level = 0.95) # to produce a confidence interval

t.test(critic_score1, mu = 76) #

t.test(critic_score1, mu = 7.44) #

```


### Analysis 2: One Proportion - Genre
#### Analyst:Daniel Gurwah
In terms of the central limit theorem, I believe it does not pass the condition of a being a simple random sample. However it does pass the conditions of being less than 10% of the population and there are at least 10 success and 10 failures.
The parameter I investigated was the categorical variable genre. For the purpose of our test the category "fighting" in the genre variable was used as a success and the rest of them were counted as failures. There were 849 successes, which is about 5.1% of the sample size. There were 15868 failures, which is about 94.9% of the sample size. After calculating a confidence interval, we are 90% confident that fighting games make up **4.8% to 5.4%** of the video game population. 
```{r}
#recording the genre variable, success is a fighting game
genre_recode <- c(rep("success", 849), rep("failure", 15868))

#checking to make sure recoded properly
table(genre_recode)

#getting the 90% confidence interval
prop.test(x = 849, n = 16717, conf.level = .90)$conf.int
```


#source: https://www.statista.com/statistics/189592/breakdown-of-us-video-game-sales-2009-by-genre/

For the hypothesis test the question to answer is: Is the proportion of fighting video games sold from 1980 to 2020 (5.1%) different than the proportion of video games sold in 2018 (7.8)?
null hypothesis: Fighting games make up 7.8% of the population of video games
alternative hypothesis: fighting games do not make up 7.8% of the population of video games
We would like to test this at a 5% significance level. This will also be a two-tail test. 
Since the p-value is very small, we will reject the null hypothesis at a significance level of 5% and conclude that there is no statistically significant evidence where fighting games make up *7.8%* of the video game population. 
One limitation of our sample is that we do not include information or data on mobile games on the google play and ios store. 
```{r}
#hyothesis test
prop.test(x = 849, n = 16717, p = 0.078, alternative = "two.sided")$p.value
```




### Analysis 3: Two Proportions - [Genre and Rating]
#### Analyst:[Joseph diFrancesco]

For this analysis, I believe the explanatory variable is the Rating because with the filtered dataset, Rating is independent and a set number of games. The response variable is Genre because within the dataset the number of games in shooter and action are dependent on the rating being M.The parameter I investigated was the proportions between Action games rated M and Shooter games rated M. I found that 608 action games were rated M, and 565 shooter games were rated M. For the confidence interval, we are 99% confident that the difference of action games rated M and shooter games rated M is between 24.6% and 54.1%. The null hypothesis of this data set is that pvalue < significance level, which in this case is 0.05 or 5%. The alternative hypothesis is that the pvalue > significance level. I am using a two sided test because I am testing whether the sample is greater than or less than the p value. The test statistic for this data set is -1.776, the p value is 0.07, and I fail to reject the null hypothesis because the p value is greater than the significance level. The confidence interval of the hypothesis tests confirms rejecting the null hypothesis because the interval contains 0.

```{r}
#Condensing data to all games that are rated M and all
#shooter and action games rated M
ratedm <- vgs %>%
  select(Rating, Genre) %>%
  filter(Rating == "M") %>%
  filter(Genre == "Shooter" | Genre == "Action")
#Creating a summary making sure the data was filtered correctly
summary(ratedm)
#Getting a 99% confidence interval, with x = (608 action games rated M - 565 shooter games rated M)
prop.test(x = 43, n = 1173, conf.level = 0.99)
#Creating a hypothesis test
t.test(ratedm$Genre=='Shooter', ratedm$Genre=='Action', alternative = 'two.sided', conf.level = .99)

```




### Analysis 4:Two Independent Means - [Name or description of your Variable]
#### Analyst:[Christopher Aguila]

The variables chosen for this analysis are North American Sales (NA_Sales), which is a quantitative variable, and Platform, which is a categorical variable. The platform variable has been reclassified to only include the console platforms of Playstation 3 and Xbox 360. These two groups are independent as there is no relation between the North American sales for each platform. The explanatory variable in this situation would be the type of platform and the response variable would be the North American sales for each platform. Through calculating the confidence interval below, we
are 95% confident that the true difference in North American sales for the PS3
and Xbox 360 is between .21 and .06. Note that the confidence interval is
negative, which indicates that there were less North American sales for the PS3
platform than the Xbox 360 platform.

For my Hypothesis Test, I have designated the null hypothesis as: The true difference between North American sales for PS3 and Xbox360 is equal to 0. Furthermore, I have
designated the alternative hypothesis as: The true difference between North American sales for PS3 and Xbox 360 is not equal to 0. The shapiro test returned a p-value much less than the significance level of 0.05, so a t test was needed to be conducted for the hypothesis test. This is a two tail test because our alternative hypothesis is that there is only a non zero difference. If I had specified that the true difference is greater than 0 or less than 0 for the alternative hypothesis, it would have been a one tail test. The t test calculates a t value of -3.5 and a p value of .0004. With the p-value being smaller than the significance level of 0.05, we
can reject the null hypothesis. 


The 95% confidence interval, alongside the hypothesis test and the negative
true difference they calculate corroborate to show
that there are less North American sales for the PS3 platform than for the Xbox 360 platform.

```{r}
#Subsetting from video game dataset, where NA's are excluded and only PS3
# and x360 platforms are included.
nasplt <- vgs %>%
  select(NA_Sales, Platform) %>%
  filter(!is.na(NA_Sales)) %>%
  filter(Platform == "PS3" | Platform == "X360")
#viewing summary of subsetted data
summary(nasplt)
nasplt %>%
  group_by(Platform)%>%
  summarize(n(),mean(NA_Sales), sd(NA_Sales))

+#visualizing data as a boxplot
ggplot(data = nasplt, mapping = aes(x = Platform, y = NA_Sales)) +
  geom_boxplot()

#Testing data for normailty
shapiro.test(nasplt$NA_Sales[nasplt$Platform=="PS3"])
shapiro.test(nasplt$NA_Sales[nasplt$Platform=="X360"])

#Generating the confidence interval as well as hypothesis test.
t.test(NA_Sales ~ Platform, data = nasplt, var.equal = TRUE)
```




### Analysis 5: Paired Data - NA_Sales and EU_Sales
#### Analyst: Samson Joseph

The variables chosen for this analysis are NA_Sales and EU_Sales. These two are quantitative variables that are paired because of different geographic regions. They are paired because we are trying to analyze the sales of the same games in different regions. We will be measuring the difference, or lack there of, of video game sales in these two regions. Then the explanatory variable is the region, and the response is the number of sales. In order to find the 95% confidence interval, we need to make sure we can use the CLT. The values are independent, since the sale of one game does not really affect the sale of another. The values were randomly chosen, and the dataset contains less than 10% of all video games sold.We get a confidence interval of approximately (0.1129 , 0.1567). In other words, we are 95% confident that the true difference between the sales of video games in North America and the EU is between 112,900 and 156,700, since the sales in the dataset are in the millions. Suggesting that more video games are sold in North America than in the EU.

Since the shapiro test returned a p-value much less than 0.05, we need to use the t-distribution for the hypothesis test.There is a possibility the difference we got was simply due to chance, and in fact the number of sales should be the same. So we can do a hypothesis test, with a null and alternative hypotheses. The null will be, the true difference between North America and the EU is 0, and the alternative will be the true difference not being 0. This is a two-tail test, since the alternative hypothesis says the true difference is not equal to 0, instead of either greater than or less than the null value which would require a one-tail test. After doing the t-test, we get a t-value of about 12 and a p-value of 2.2e-16. That p-value is extremely smaller than our significance value of 0.05. This means we should reject the null hypothesis. Since the probability of getting the observed mean of about 0.13, given the null hypothesis, is much smaller than 0.05.

Given the analysis of paired means, NA_Sales and EU_Sales, we can conclude that more games are sold in North America than in the European Union.This conclusion is corroborated by the 95% confidence interval and the hypothesis test. Both suggest a true difference that is positive, in favor favor of North America.

```{r warning=FALSE}
#Setting up necessary Dataframes.
#Randomly sampled 10,000 values from NA_Sales and EU_Sales so we could find the difference without any errors due to row lengths.
EU_Sales_A5 <- data.frame(EU_Sales=vgs$EU_Sales[!is.na(vgs$EU_Sales)])
EU_Sales_A5 <- data.frame(sample_n(EU_Sales_A5, 10000), replace=FALSE)
NA_sales_A5 <- data.frame(NA_Sales=vgs$NA_Sales[!is.na(vgs$NA_Sales)])
NA_sales_A5<-data.frame(sample_n(NA_sales_A5, 10000), replace=FALSE)

#Creating boxplots to view the spread of the data in both dataframes.
#They y values are limited from 0 to 0.42 because 0.42 is the cutoff for outliers in NA_Sales. The same value was used for the EU_Sales boxplot to help compare the two datasets.  
ggplot(EU_Sales_A5, aes(x='',EU_Sales), ) + geom_boxplot() + ylim(0,.42) + ylab('EU Sales')
ggplot(NA_sales_A5,aes(x='',NA_Sales)) + geom_boxplot() + ylim(0,.42) +ylab('NA Sales')

#Creating a new dataframe to create a Diff column, with the difference between NA_Sales and EU_Sales
NA_EU_Sales <- data.frame(NA_Sales=NA_sales_A5$NA_Sales, EU_Sales=EU_Sales_A5$EU_Sales) 
NA_EU_Sales$Diff <- NA_EU_Sales$NA_Sales - NA_EU_Sales$EU_Sales

#Creating a histogram to see the spread of the Diff column
ggplot(NA_EU_Sales, aes(x=Diff)) + 
  geom_histogram(binwidth = .1) + xlim(-5,7)

#Testing for normality
shapiro.test(sample(NA_EU_Sales$Diff,5000, replace=FALSE))
qqnorm(NA_EU_Sales$Diff)
qqline(NA_EU_Sales$Diff)

#Creating a 95% confidence interval
inference(Diff, data=NA_EU_Sales, statistic = 'mean', type = 'ci', method = 'theoretical')

#Doing a t-test for the difference in the means.
t.test(NA_EU_Sales$NA_Sales, NA_EU_Sales$EU_Sales, paired = TRUE, alternative = 'two.sided')

```





## Recommendations

[Add text section with your recommendations here. In this section, you will briefly  summarize the conclusions of your estimates and tests. What statistically significant findings did you have?  What limitations are there in your findings?  Discuss if/how this is relevant in the context of your data – does it give us new insights ? Help us to better understand some phenomenon?  Or not?]


